{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba44301-c1ab-4e21-9215-788180e4c9b2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#1a49b5\"><center>Exploration approfondie des bases de donn√©es NoSQL : Une plong√©e dans le monde de MongoDB et Redis</center></h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae0547-a174-4b4b-8c62-17d3128f1e05",
   "metadata": {},
   "source": [
    "<h2>Table des mati√®res:</h2>\n",
    "<h4>Introduction</h4>\n",
    "<h4>I. la D√©normalisation</h4>\n",
    "1. √âtude de cas<br>\n",
    "2. La tranformation des fichiers<br>\n",
    "3. La jointure sur des objets JSON<br>\n",
    "<h4>II. D√©couverte de la base de donn√©e Redis</h4>\n",
    "1. Installation de Redis<br>\n",
    "2. Connecter √† Redis avec Python<br>\n",
    "3. Les commandes fondammentales<br>\n",
    "4. Bloom Filter<br>\n",
    "5. √âtude des performances de Redis<br>\n",
    "6. Publication et souscription<br>\n",
    "<h4>III. D√©couverte de la base de donn√©e MongoDB</h4>\n",
    "1. Installation de MongoDB<br>\n",
    "2. Commandes fondamentales de MongoDB<br>\n",
    "3. Les commandes fondammentales<br>\n",
    "4. La jointure des Objets JSON avec MongoDB<br>\n",
    "5. √âtude des performances de MongoDB<br>\n",
    "6. Publication et souscription<br>\n",
    "\n",
    "<h4>Conclusion</h4>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442832ae-5934-4056-940a-1562c99a5f3d",
   "metadata": {},
   "source": [
    "<h3>Introduction:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ac479-5a02-47d7-ab9c-807eab183466",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Les syst√®mes de gestion de base de donn√©es traditionnels ont longtemps domin√© le paysage informatique, mais avec l'√©volution rapide des applications modernes, de nouvelles approches sont n√©cessaires pour r√©pondre aux exigences de performances et de flexibilit√© croissantes. Parmi ces approches novatrices, les bases de donn√©es NoSQL √©mergent comme des solutions puissantes, d√©passant les limites des mod√®les relationnels classiques. Dans ce contexte, notre compte rendu se penchera sur deux acteurs majeurs du monde NoSQL : MongoDB et Redis.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Notre exploration approfondie des bases de donn√©es NoSQL, se centrera sur un √©l√©ment cl√© de leur architecture : la d√©normalisation des tables. Avant d'approfondir ce concept essentiel, nous examinerons de pr√®s les raisons et les crit√®res sous-tendant la d√©normalisation. Cette d√©marche pr√©liminaire jettera les bases n√©cessaires pour une compr√©hension approfondie des avantages et des implications de cette approche dans le contexte de MongoDB et Redis.\n",
    "\n",
    "La prochaine √©tape nous conduira √† explorer en d√©tail les commandes de base de Redis, mettant en exergue une m√©thode tout particuli√®rement fascinante : le filtre de Bloom. Cette approche s'av√®re √™tre une m√©thode efficace pour optimiser les op√©rations de stockage et de recherche, ajoutant une dimension intrigante √† notre exploration de cette base de donn√©es en m√©moire.\n",
    "\n",
    "La route de notre exploration se poursuivra avec une √©valuation minutieuse de la performance de Redis, mettant l'accent sur son comportement face √† des ensembles de donn√©es d√©passant les 100 000 √©l√©ments. Cette analyse approfondie jettera une lumi√®re pr√©cise sur la capacit√© de Redis √† √©voluer de mani√®re agile et performante dans des contextes de traitement de donn√©es massives.\n",
    "\n",
    "Nous plongerons ensuite dans l'univers riche de MongoDB, explorant ses commandes fondamentales et scrutant sa performance dans divers contextes d'utilisation. Cette incursion dans la base de donn√©es orient√©e document nous permettra de saisir les nuances de son approche flexible ax√©e sur la gestion de donn√©es non structur√©es.\n",
    "\n",
    "Enfin, notre √©tude atteindra son apog√©e avec une comparaison de la performance entre Redis et MongoDB. Cette analyse comparative soulignera les avantages et les sp√©cificit√©s de chaque solution, offrant une vision √©clair√©e pour ceux qui recherchent des solutions NoSQL adapt√©es √† leurs besoins sp√©cifiques. Pr√©parez-vous √† d√©couvrir comment MongoDB et Redis, en combinant souplesse et performance, tracent la voie vers l'avenir de la gestion des informations, r√©pondant ainsi aux d√©fis complexes pos√©s par les applications modernes.\n",
    "</p>\n",
    "Accrochez-vous, c'est parti! üöÄ \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6507e-e697-4f8d-801c-8a324aa7f44b",
   "metadata": {},
   "source": [
    "<h2>I. La d√©normalisation:</h2>\n",
    "<p style=\"text-align: justify\"> \n",
    "La d√©normalisation est une technique de conception de bases de donn√©es qui consiste √† regrouper des tables relationnelles initialement normalis√©es pour former une structure plus plate et moins normalis√©e. Cette approche vise √† am√©liorer les performances en r√©duisant le nombre de jointures n√©cessaires lors des requ√™tes. Contrairement √† la normalisation, qui cherche √† organiser les donn√©es pour minimiser la redondance.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17de6e8-efdf-4523-aee5-b4b259fe0329",
   "metadata": {},
   "source": [
    "<h3>1. √âtude de cas:</h3>\n",
    "<p style=\"text-align: justify\">\n",
    "Afin de mieux comprendre les avantages de la d√©normalisation, consid√©rons le mod√®le relationnel pour une compagnie a√©rienne pr√©sent√© dans <B>la figure 1</B>. Cette d√©marche nous permettre de saisir les raisons sous-jacentes √† l'utilisation de la d√©normalisation et de comprendre son lien avec les bases de donn√©es NoSQL.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Imaginons une situation ou la compagnie a√©rienne souhaite am√©liorer la performance lors de l'affichage des d√©tails d'un vol, y compris les informations sur l'avion, le pilote et la reservation associ√©es. Dans ce mod√®le normalis√©, cela impliquerait des op√©ration de jointure complexes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d657b5-a668-46ad-b580-e0829bd75d21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image1.png\"\n",
    "  alt=\"Mod√®le de donn√©es normalis√© pour une companie a√©rienne\"\n",
    "  width=\"600\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 1: Mod√®le de donn√©es normalis√© pour une companie a√©rienne<b></h5>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a60c54-f0a7-43d6-9e1a-a4a122f84c91",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: justify\">\n",
    "Comment pouvons-nous d√©normaliser notre Base de donn√©es ?\n",
    "</h3>\n",
    "<p >\n",
    "Voici quelques pistes √† appliquer pour d√©normaliser notre base de donn√©es :\n",
    "</p>\n",
    "   \n",
    "<h4 style=\"color:#3866b8;\">1. Des donn√©es fr√©quemment interrog√©es conjointement:</h4>\n",
    "<p style=\"text-align: justify\">\n",
    "Dans le cas de nos tables, si nous effectuons fr√©quemment des requ√™tes qui n√©cessitent des informations sur les vols, les r√©servations et les classes de mani√®re conjointe, nous pourrions envisager de d√©normaliser en regroupant ces donn√©es dans une seule table, par exemple une table nomm√©e \"InfoVols\". Ainsi, au lieu de faire des jointures, vous auriez toutes les informations n√©cessaires dans une seule table.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"color:#3866b8;\">2. Toutes les donn√©es d‚Äôune entit√© sont ind√©pendantes:</h4>\n",
    "<p style=\"text-align: justify\">\n",
    "Si les donn√©es des vols, des avions, des pilotes, des clients, des classes et des r√©servations sont relativement ind√©pendantes les unes des autres, nous pourrions envisager une d√©normalisation en regroupant ces donn√©es dans une table \"InfoVols\", √©vitant ainsi des jointures fr√©quentes.</p>\n",
    "\n",
    "<h4 style=\"color:#3866b8;\">3. Une association avec des relations 1-n des deux c√¥t√©s:</h4>\n",
    "<p style=\"text-align: justify\">\n",
    "Si vous avez des associations avec des relations 1-n des deux c√¥t√©s, par exemple entre les vols et les r√©servations, vous pourriez envisager une d√©normalisation en int√©grant les r√©servations directement dans la table \"InfoVols\", repr√©sent√©e par : ‚Äú[{NumCl, Classe, NbPlaces}]‚Äù.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"color:#3866b8;\">4. M√™me taux de mises √† jour:</h4>\n",
    "<p style=\"text-align: justify;\">\n",
    "Si les taux de mise √† jour des diff√©rentes entit√©s (vol, avion, pilote, client, etc.) sont √©quivalents, vous pourriez envisager une d√©normalisation plus pouss√©e en regroupant toutes les donn√©es dans une table \"InfoVols\" pr√©sent√© dans <b>la figure 2</b>, simplifiant ainsi la gestion des mises √† jour.\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e214c3d6-440f-4710-b41a-4797a9102b3e",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image2.png\"\n",
    "  alt=\"Repr√©sentation de la table  d√©normalis√©e\"\n",
    "  width=\"500\"\n",
    "  height=\"400\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 2: Repr√©sentation de la table  d√©normalis√©e<b></h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd9ea6-137a-43e2-b2df-4745641d62dc",
   "metadata": {},
   "source": [
    "<h3>R√©sultat:</h3>\n",
    "<p style=\"text-align: justify\">\n",
    "L'impl√©mentation concr√®te notre d√©normalisation est expos√©e dans <b>la figure 3</b>, sous forme de repr√©sentation JSON. Cela sugg√®re que la d√©normalisation a √©t√© r√©alis√©e en regroupant les informations n√©cessaires dans une seule structure de donn√©es, √©liminant ainsi la n√©cessit√© de faire des jointures lors de la r√©cup√©ration des d√©tails d'un vol.\n",
    "</p>\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image3.png\"\n",
    "  alt=\"Repr√©sentation JSON de la d√©normalisation\"\n",
    "  width=\"600\"\n",
    "  height=\"400\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Figure 3: Repr√©sentation JSON de la d√©normalisation<b></h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c9d07-9546-4813-8ae5-bc990deedde9",
   "metadata": {},
   "source": [
    "<h3>Conclusion:</h3>\n",
    "<p style=\"text-align: justify\">\n",
    "La d√©normalisation s'inscrit parfaitement dans l'environnement NoSQL. Ce mod√®le d√©normalis√© offre la flexibilit√© n√©cessaire pour stocker des donn√©es de mani√®re √† optimiser les requ√™tes sans √™tre limit√© par une structure de sch√©ma rigide.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43141f-e09d-4ba9-81a5-611146625a2d",
   "metadata": {},
   "source": [
    "<h3>2. La tranformation des fichiers:</h3>\n",
    "<h4>2.1. Transformation des fichiers txt aux fichiers csv:</h4>\n",
    "<p style=\"text-align: justify\">\n",
    "Dans cette partie, nous aborderons le processus de transformation d'un fichier au format TXT contenant des donn√©es sur les avions vers un format CSV, en vue de l'int√©grer dans la base de donn√©es. Pour ce faire, nous utilisons le langage de programmation Python et la biblioth√®que pandas. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ba89a-a56b-4c0e-a1c4-f83612fb5934",
   "metadata": {},
   "source": [
    "***Fichier_text:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b26745-8367-4764-9ee6-46a5d1c7694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\t Boeing 727\t150\tMarseille\n",
      "\n",
      "250\tBoeing 747\t500\tParis\n",
      "\n",
      "269\tBoeing 737\t300\tParis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"txt/AVIONS.txt\", 'r') as file_avion:\n",
    "    lignes = file_avion.readlines()\n",
    "    for index, ligne in enumerate(lignes):\n",
    "        print(ligne)\n",
    "        if index==2:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312bc33-85f9-48a0-9d73-58ca77e90cb4",
   "metadata": {},
   "source": [
    "***M√©thode_de_transformation:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a0bff9-11c6-4388-ab58-409e7c0291aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_avion = pd.read_csv ('txt/AVIONS.txt', sep='\\t')\n",
    "headers =  [\"NumAv\", \"NomAv\", \"CapAv\", \"VilleAv\"]\n",
    "file_avion.columns = headers\n",
    "file_avion.to_csv ('csv/AVIONS.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f57338-5b5b-4008-8b81-ab48668ac178",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Le code commence par lire le fichier \"AVIONS.txt\" avec la fonction \"read_csv\" de pandas, en sp√©cifiant que les donn√©es sont s√©par√©es par des tabulations. Ensuite, des libell√©s de colonnes appropri√©s sont d√©finis dans une liste appel√©e \"headers\", ces libell√©s sont appliqu√©s au DataFrame r√©sultant.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Le DataFrame modifi√© est ensuite sauvegard√© dans un fichier CSV \"AVIONS.csv\" dans le r√©pertoire \"csv\", en utilisant la fonction \"to_csv\" de pandas. Le param√®tre \"index=None\" indique de ne pas inclure les indices de lignes dans le fichier CSV r√©sultant.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb9291-3a08-4813-9ebd-18e2a741f926",
   "metadata": {},
   "source": [
    "***R√©sultat:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c099a7e5-ee96-4e20-9c31-1aa2303e0a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumAv</th>\n",
       "      <th>NomAv</th>\n",
       "      <th>CapAv</th>\n",
       "      <th>VilleAv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>Boeing 747</td>\n",
       "      <td>500</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>300</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>300</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumAv       NomAv  CapAv VilleAv\n",
       "0    250  Boeing 747    500   Paris\n",
       "1    269  Boeing 737    300   Paris\n",
       "2    240  Boeing 737    300   Paris"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv/AVIONS.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a46ec-e8f4-4348-a7c0-bb78111f180a",
   "metadata": {},
   "source": [
    "<p>\n",
    "Ce processus de la transformation cruciale pour pr√©parer les donn√©es afin de les int√©grer efficacement dans la base donn√©es.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da3a3d-489b-4c48-8cc1-4cfe536181b3",
   "metadata": {},
   "source": [
    "  <h4>2.2. Transformation des fichiers CSV aux fichiers JSON:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013cf11b-d558-4dbd-b071-8dab77f6d004",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">Dans la phase de pr√©paration de notre syst√®me pour l'utilisation de bases de donn√©es NoSQL(MongoDB et Redis), une √©tape importante consiste √† convertir notre jeu de donn√©es, initialement stock√© au format CSV, vers un format JSON.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Cette op√©ration est r√©alis√©e en utilisant aussi la bibiloth√©que <b>pandans</b> en Python. La transformation s'effectue de mani√®re simple et efficace grace √† la m√©thode \"to_json\" de pandas:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c84de0-ba04-45b3-b55e-5a9931958a1d",
   "metadata": {},
   "source": [
    "***M√©thode_de_transformation:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a57d52-7c4c-441e-90b6-ce733ad2628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"json/Avions.json\", orient='records')\n",
    "#Affichage JSON\n",
    "#df = pd.read_json(\"json/koko.json\")\n",
    "#df.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144d15-ddea-4e22-8320-f06489c9ddb2",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Dans cette commande \"df\" repr√©sente le DataFrame pandas qui contenait les donn√©es extraites du fichier CSV. L'argument <b>\" json/avions.json \"</b> sp√©cifie le chemin et le nom du fichier JSON r√©sultant dans lequel les donn√©es converties seront enregistr√©es. L'argument <b>\" orient='records' \"</b> sp√©cifie que chaque enregistrement du DataFrame est repr√©sent√© comme un objet JSON distinct dans le fichier r√©sultant.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Cette conversion pr√©pare nos donn√©es pour √™tre facilement ing√©r√©es pas les bases de donn√©es NoSQL. Le format JSON offre une repr√©sentation adapt√©e a ces bases de donn√©es, facilitant ainsi l'insertion, la mise √† jour et la requete de donn√©es coplexes.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "En proc√©dant de la sorte, notre syst√®me est pr√™t √† exploiter aux mieux les fonctionnalit√©s de stockage et de r√©cup√©ration de nos bases de donn√©es(MongoDB et Redis) et ainsi une gestion efficace et performante de nos donn√©es.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34cfb8-85cd-4ebe-8c15-cdfbff5912ae",
   "metadata": {},
   "source": [
    "<h3>3. La jointure sur des objets JSON:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d2cef-7f85-49db-bf35-f8c12c808af7",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Dans cette partie, nous aborderons une √©tape cruciale de pr√©paration des donn√©es pour les integr√©s dans une base de donn√©s NoSQL. Notre objectif est d'effectuer une jointure entre deux fichiers JSON, en utilisant un attribut commun, suivi d'une fonction d'une op√©ration de d√©normalisation pour simplifier la structure des donn√©es.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab29945-735b-467c-8f29-34df64acbc73",
   "metadata": {},
   "source": [
    "***√âtape 1: chargement des fichiers JSON (fonction facultatif)***<br>\n",
    "<p>La fonction <b>readJsonFile</b>, nous permet de charger un fichier JSON √† partir de de son chemin.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8d5f86-2983-4606-bd95-8f19af578857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJsonFile(jsonPath):\n",
    "    with open(jsonPath) as f:\n",
    "        jsonified = json.load(f)\n",
    "        return jsonified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595a76e-1c0a-4979-9fbf-09f568c3f7bd",
   "metadata": {},
   "source": [
    "***√âtape 2: Jointure des fichiers JSON***<br>\n",
    "<p>\n",
    "La fonction <b>jointure</b> prend deux fichiers JSON ainsi qu'un attribut commun. Elle r√©alise une jointure des deux fichiers o√π la valeur de l'attribut commun est identique.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c5c9ba-2dc2-49ec-ad68-df0262eaf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jointure(json1, json2, key):\n",
    "    file=[]\n",
    "    for lineJson1 in json1:\n",
    "        for lineJson2 in json2:\n",
    "            if lineJson1[key]==lineJson2[key]:\n",
    "                concatenateLines = lineJson1.copy()\n",
    "                concatenateLines.update(lineJson2)\n",
    "                file.append(concatenateLines)\n",
    "    return file   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58080325-7f9b-41f8-9ae2-054a8c2e9254",
   "metadata": {},
   "source": [
    "***√âtape 3: La d√©normalisation des donn√©es***<br>\n",
    "<p>Cette fonction r√©alise la d√©normalisation des donn√©s en regroupant les objets qui partagent la m√™me valeur pour une cl√© sp√©cifi√©e.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b305dd21-dd9a-4a85-ac36-ea81a78f68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import groupby\n",
    "\n",
    "def denormalizeJsonByKey(json, key):\n",
    "    data=sorted(json, key=lambda x: x[key])\n",
    "    jsonResult = {}\n",
    "    for groupKey, group in groupby(data, key=lambda x: x.get(key, '')):\n",
    "        groupList = list(group)\n",
    "        size = (len(groupList))\n",
    "        if size == 1:\n",
    "            jsonResult[groupKey] = groupList[0]\n",
    "        else:\n",
    "            keysList = list(groupList[0].keys())\n",
    "            result = {}\n",
    "            for keyDict in keysList:\n",
    "                if keyDict == key :\n",
    "                    result[keyDict] = groupKey\n",
    "                else:\n",
    "                    result[keyDict] = []\n",
    "        \n",
    "            for obj in groupList:\n",
    "                for keyDict2, value in obj.items():\n",
    "                    if keyDict2 != key and value not in result[keyDict2]:\n",
    "                        result[keyDict2].append(value)\n",
    "            jsonResult[groupKey] = result\n",
    "        \n",
    "    return list(jsonResult.values())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf1149-cd11-42e4-b8c1-2549195f91e8",
   "metadata": {},
   "source": [
    "***√âtape 4: test***<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583258f3-fcce-4306-bf28-9f513e4fea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"cle\"\n",
    "json1 = readJsonFile(\"json/json1.json\")\n",
    "json2 = readJsonFile(\"json/json2.json\")\n",
    "combined = jointure(json1, json2, key)\n",
    "denormalize=denormalizeJsonByKey(combined,key)\n",
    "#print(denormalize)\n",
    "\n",
    "chemin_fichier_json = \"json/new_file.json\"\n",
    "with open(chemin_fichier_json, 'w') as file:\n",
    "    json.dump(denormalize, file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8daa06-daee-49ed-9b99-133a2caeeea8",
   "metadata": {},
   "source": [
    "***Conclusion***<p>\n",
    "    En conclusion, cette approche de jointure et de d√©normalisation constitue une √©tape essentielle pour pr√©parer les donn√©es en vue de leur int√©gration dans une BD NoSQL.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f84b7-f628-453d-abe2-f63a69b5e9bf",
   "metadata": {},
   "source": [
    "<h1>II. D√©couverte de la base de donn√©e Redis:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5fe804-5912-430b-bb60-0fe21be849aa",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "Dans cette section, nous plongerons dans Redis, un syst√®me de gestion de donn√©es, con√ßu pour stocker, r√©cup√©rer et manipuler diff√©rents types de donn√©es. Il s‚Äôagit d‚Äôune base de donn√©es NoSQL de type paire cl√©/valeur. \n",
    "<p style=\"text-align: justify\">\n",
    "<b>Note importante: </b>Une des principales caract√©ristiques de Redis est de conserver l'int√©gralit√© des donn√©es en RAM. Cela permet d'obtenir d'excellentes performances en √©vitant les acc√®s disques, particuli√®rement co√ªteux. Pour garantir la pr√©servation des donn√©es en cas d'incident, compte tenu de la volatilit√© de la m√©moire vive, Redis propose la fonctionnalit√© de \"capturer\" l'√©tat de la base dans un fichier. Bien que cette technique ne retienne pas les modifications apport√©es entres deux captures, elle offre √©galement la possibilit√© de les enregistrer, ainsi la restauration de la base en cas de n√©cessite. \n",
    "<p style=\"text-align: justify\">\n",
    "Pr√©parez-vous √† explorer le monde de Redis! On va d√©couvrir ses utilisations, ses fonctionnalit√©s, ses performances et bien s√ªr son service publish/subscribe ultra efficace.\n",
    "</p>\n",
    "</p>\n",
    "<h3>1. Installation de Redis:</h3>\n",
    "<p style=\"text-align: justify\">\n",
    "La proc√©dure d√©taill√©e est disponible dans <b>les Annexes 1 </b>et<b> 2</b>. Nous avons choisi d'utiliser Docker pour le d√©ploiement de Redis en raison de sa facilit√© d'utilisation. Pour ce faire, nous avons cr√©e un Dockerfile. De plus Docker Compose qui orchestre le d√©ploiement de notre application.\n",
    "</p>\n",
    "<p style=\"text-align: justify\">\n",
    "Une alternative pour interagir avec Redis est d'utiliser RedisInsight, une interface graphique conviviale simplifie la gestion et la visualisation des donn√©e Redis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd36e8f-f0e9-48fd-9a6e-4cd31700e443",
   "metadata": {},
   "source": [
    "<h3>2. Connecter √† Redis avec Python:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5ecad-2458-4cfd-9629-b34525c4482b",
   "metadata": {},
   "source": [
    "<p>Pour interagir avec Redis, la premi√®re √©tape est la connexion:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d738fa8a-780c-47aa-8337-69c72cf96eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "client_redis = redis.Redis(host='localhost', port=6379)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd7eec-d652-481e-9490-f6bddc0e4b87",
   "metadata": {},
   "source": [
    "<h3>3. Les commandes fondammentales:</h3>\n",
    "<h4>3.1. Stockez et r√©cup√©rez les donn√©es:</h4>\n",
    "<h5>3.1.1 Une cha√Æne simple:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d80b059-3c9a-4b89-b531-967bee3af31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'karam'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stockez\n",
    "client_redis.set('name', 'karam')\n",
    "\n",
    "#R√©cup√©rez\n",
    "client_redis.get('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad3d12-7a27-45b9-aab9-71a0c6e2a096",
   "metadata": {},
   "source": [
    "<h5>3.1.2 Un dictionnaire:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40037ef-40ce-4682-b461-d5ede981b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'name': b'karam', b'surname': b'bekkali', b'age': b'30'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stockez\n",
    "client_redis.hset('users', mapping={\n",
    "    'name': 'karam',\n",
    "    \"surname\": 'bekkali',\n",
    "    \"age\": 30\n",
    "})\n",
    "#R√©cup√©rez\n",
    "client_redis.hgetall('users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed5352-bfb1-4b44-a033-4d7b39528672",
   "metadata": {},
   "source": [
    "<h5>3.1.3 Un fichier JSON:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db790902-a778-45a6-a43e-aad0f1ab5a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cle': '001', 'lieu': 'Rane 1'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#Stockez\n",
    "with open (\"json/json1.json\") as file:\n",
    "    data=json.load(file)\n",
    "client_redis.json().set('my_json','$',data)\n",
    "\n",
    "#R√©cup√©rez\n",
    "res = client_redis.execute_command('JSON.GET', 'my_json')\n",
    "element= res[1]\n",
    "#element= res\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207f30c-9310-4b83-8cbe-bf157e76af4a",
   "metadata": {},
   "source": [
    "<p>\n",
    "<b>La figure 4</b> montre la structure JSON d'un fichier stock√© dans Redis. La repr√©sentation JSON montre les donn√©es organis√©es avec des cl√©s et des valeurs associ√©es. Les objets JSON sont repr√©sent√©s par des accolades, le tableaux par des crochets, et les paires cl√©-valeur indiquent des informations sp√©cifiques. Les donn√©es sont organis√©es de mani√®re √† permettre une r√©cup√©ration efficace en utilisant les cl√©s d√©finies.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0ab95-b62f-4fee-a0ea-36615e8255b3",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image4.png\"\n",
    "  alt=\"D√©monstration d'insertion des donn√©es dans la base de donn√©e Redis\"\n",
    "  width=\"500\"\n",
    "  height=\"400\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Figure 4: D√©monstration d'insertion des donn√©es dans la base de donn√©e Redis<b></h5>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773d669-b3d6-434e-8cc9-d2b61276b67f",
   "metadata": {},
   "source": [
    "<h3>4. Bloom Filter:</h3>\n",
    "<p>\n",
    "Un filtre bloom est une structure probabiliste des donn√©es qui permet de savoir de fa√ßon extr√™mement rapide si un √©l√©ment fait partie d‚Äôun ensemble ou pas. On entend par probabiliste, le fait que le r√©sultat ne peut qu‚Äô√™tre ‚Äúpas compris dans l‚Äôensemble‚Äù ou ‚Äú√©ventuellement compris dans l‚Äôensemble‚Äù. Il ne peut pas fournir un r√©sultat exact tel que ‚Äúoui l‚Äô√©l√©ment fait assur√©ment partie d‚Äôun ensemble‚Äù. Cela signifie que des faux positifs sont possibles mais que des faux n√©gatifs sont impossibles.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1964ff-93ef-4f96-960a-1376b5717f0d",
   "metadata": {},
   "source": [
    "<h4>4.1. Sc√©nario d'application: La d√©tection des adresses IP ind√©sirable:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64206a01-10d1-4833-b70f-b41881f36c1e",
   "metadata": {},
   "source": [
    "<p>L'objectif de cet exemple est d'explorer l'utilisation des filtres de Bloom dans le contexte de la v√©rification des adresses IP par rapport √† une liste noire.</p>\n",
    "<p>\n",
    "Dans cette d√©monstration, nous avons utilis√© l'interface en ligne de commande de RedisInsight pour mettre en oeuvre cette approche. <b>La figure 5</b> montre le processus.\n",
    "</p>\n",
    "<p>Dans cet exemple, nous avons utilis√© Bloom Filter pour v√©rifier si des adresses IP font partie d'une liste noire. Tout d'abord, nous avons cr√©e un Bloom Filter √† l'aide de la commande \"BF.RESERVE\" nomm√©e (blackListIP) avec une probabilit√© d'erreur de 0.0001 et une taille de 100 √©l√©ments.</p>\n",
    "<p>\n",
    "Ensuite, trois adresses IP ont √©t√© ajout√©es au filtre √† l'aide de la commande \"BF.MADD\". Les r√©ponses \"1\" indiquent que les trois ajouts ont r√©ussi, ce qui signifie que ces adresses IP sont maintenant consid√©r√©es comme pr√©sentes dans le filtre.\n",
    "<p>\n",
    "Pour v√©rifier si une adresse IP particuli√®re est dans la liste noire, nous avons utilis√© la commande \"BF.MEXISTS\". Lorsque l'adresse IP (89.30.99.12) a √©t√© test√©e, la r√©ponse a indiqu√© \"0\", ce qui signifie que cette adresse n'appartient pas √† la liste noire. En revanche, pour l'adresse IP (86.10.123.16), la r√©ponse a √©t√© 1, ce qui signifie que cette adresse fait partie de la liste noire.\n",
    "</p>\n",
    "<p>\n",
    "En r√©sum√©, l'utilisation du Bloom Filter ici permet de v√©rifier rapidement et de mani√®re probabiliste si une adresse IP donn√©e est pr√©sente dans une liste noire, ce qui est utile pour d√©tecter et bloquer des adresses IP ind√©sirables.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31007f40-9991-4baf-b56f-ac635f4a2139",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image5.png\"\n",
    "  alt=\"V√©rification des adresses IP dans une liste noire avec Bloom Filters\"\n",
    "  width=\"400\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Figure 5: V√©rification des adresses IP dans une liste noire avec Bloom Filters<b></h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e899d-8224-4864-8550-66b3cc190b6b",
   "metadata": {},
   "source": [
    "<h3>5. √âtude des performances de Redis:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940c469-ed00-4342-bcd2-b9f9c3654555",
   "metadata": {},
   "source": [
    "<p>\n",
    "Dans le cadre de cette √©tude, notre objectif est d'analyser la performance de Redis avec deux m√©thodes differentes, √† savoir les filtrers de Bloom et les listes, dans le contexte de la gestion de grandes quantit√©s de donn√©es. Dans cette √©tude on va utiliser le dictionnaire disponible sur le lien suivant: <a href=\"rali.iro.umontreal.ca/DEM//DEM-1_1.csv\">Cliquez ici.</a></p>\n",
    "<p>\n",
    "La probl√©matique est: Comment les filtres de Bloom et les listes se comportenet-ils lors du stockage et de la r√©cuperation de 100 000 mots ? Pour r√©pondre √† cette question, nous mettrons en oeuvre un test afin de mesurer les temps d'insertion et d'appartenance des mots pour chaque structure de donn√©es.\n",
    "</p>\n",
    "<p>\n",
    "Dans cette d√©marche comparative, nous cherchons √† d√©terminer laquelle des m√©thodes offre la meilleure performance en termes de temps d'acc√®s et de r√©ponses.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49900c-7e58-49ec-9f0a-abbd80995e3b",
   "metadata": {},
   "source": [
    "***Premi√®re √©tape: Pr√©paration du travail***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcefd1-a943-4488-87bb-8dfcd1e4a745",
   "metadata": {},
   "source": [
    "<p>Avant de commmencer on va convertir le fichier CSV vers un format JSON en mettant particuli√®rement l'accent sur deux cl√©s essentielles: mot \"M\" et d√©finition \"SENS\". Le choix du format JSON a √©t√© par sa capacit√© √† repr√©senter des informations complexes et √† sa flexibilit√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70de75eb-9021-4d6f-84cb-d6932ade3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Charger le fichier CSV et S√©lectionner juste les deux colonnes\n",
    "df = pd.read_csv(\"csv/test.csv\", delimiter = '\\t', usecols=['M', 'SENS'])\n",
    "\n",
    "# Convertir le DataFrame s√©lectionn√© en format JSON\n",
    "json_data = df.to_json(orient='records', force_ascii=False)\n",
    "\n",
    "# √âcrire le fichier JSON\n",
    "json_file_path = 'json/my_json.json'\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "# V√©rifier la transformation\n",
    "with open('json/my_json.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "#for item in data[:3]:\n",
    "    #print(item.get('M'))\n",
    "    #print(item.get('SENS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d139f-3606-46b7-b754-43c6f1f82505",
   "metadata": {},
   "source": [
    "***Deuxi√®me √©tape: Gestion des √©lements nuls***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50ee75-4541-425c-970b-0ffc13350ba2",
   "metadata": {},
   "source": [
    "<p>\n",
    "Apr√®s avoir accompli la premi√®re √©tape (la conversion du fichier CSV vers un fichier JSON), une observation cruciale a √©t√© faite, c'est que le fichier contient des √©l√©ments nuls  qui peuveut entrainer des probl√®mes lors de l'insertion des donn√©es dans Redis que ce soit la mani√®re utiliser (Bloom filter ou liste). C'est pour √ßa on va impl√©menter une m√©thode qui permet de filter les √©l√©ments nuls.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fdf38c8-93b5-4856-88e5-30335b8683e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(iterable):\n",
    "    return [element for element in iterable if element is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f681529a-365e-4e7f-af43-36b53466688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('json/my_json.json')\n",
    "mots_definitions = to_list(df['M'].tolist())\n",
    "definitions = to_list(df['SENS'].tolist())\n",
    "\n",
    "#Jointure\n",
    "mots_definitions.extend(definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f016d-1741-4634-ab3a-5d5a13a183ae",
   "metadata": {},
   "source": [
    "***Trois√®me √©tape: √âtude de la performance avec Bloom filter:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4056e0f-737c-40e2-84c4-e422efd8577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import time\n",
    "\n",
    "client_redis = redis.Redis(host='localhost', port=6379)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb348e12-d448-40a1-bd1a-d8f71ce334c8",
   "metadata": {},
   "source": [
    "<h5>M√©thode d'insertion avec bloom filter:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2be8322-0604-4828-a490-207b9eff4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'insertion pour bloom filter est: 1.1293649673461914 secondes\n"
     ]
    }
   ],
   "source": [
    "def insert_bloomfilter(list):    \n",
    "    BLOOM_FILTER_KEY = \"words:bloom_filter\"\n",
    "    client_redis.bf().reserve(BLOOM_FILTER_KEY, 0.01, len(list))\n",
    "    start_time = time.time()\n",
    "    client_redis.bf().madd(BLOOM_FILTER_KEY, *list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return print(f\"Temps d'insertion pour bloom filter est: {elapsed_time} secondes\")\n",
    "\n",
    "#Test\n",
    "insert_bloomfilter(mots_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4abaf-eacc-4c49-9082-5a32c9ba975a",
   "metadata": {},
   "source": [
    "<h5>M√©thode de recherche avec bloom filter:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dc7deae-01be-4dcc-9768-18fea4b270b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps pour bloom filter : 0.003640890121459961 secondes\n"
     ]
    }
   ],
   "source": [
    "def search_bloomfilter(redis_client, list, bloomfilter_key):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = redis_client.bf().mexists(bloomfilter_key, *element)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Temps d'appartenance avec bloom filter est : {elapsed_time} secondes\")\n",
    "\n",
    "my_bloom_filter= \"words:bloom_filter\"\n",
    "value_to_search = mots_definitions[len(mots_definitions)-1]\n",
    "\n",
    "#Test\n",
    "search_bloomfilter(client_redis, mots_definitions, list_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3328ca-4405-4cff-ad4a-89e050507743",
   "metadata": {},
   "source": [
    "***Quatri√®me √©tape: √âtude de la performance avec les listes:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46df91-67f9-4be2-a34a-0dd3b1db1fb3",
   "metadata": {},
   "source": [
    "<h5>M√©thode d'insertion avec liste:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00fbd3c0-dcee-4a08-be5d-26eea93196d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'insertion pour une liste : 0.8318448066711426 secondes\n"
     ]
    }
   ],
   "source": [
    "#M√©thode d'insertion avec les listes\n",
    "def insert_list(list):    \n",
    "    LIST_KEY = \"words:list\"\n",
    "    start_time = time.time()\n",
    "    client_redis.rpush(LIST_KEY, *list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return print(f\"Temps d'insertion pour une liste : {elapsed_time} secondes\")\n",
    "    \n",
    "#Test\n",
    "insert_list(mots_definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712fef4f-cc09-4070-9206-248eb81fb352",
   "metadata": {},
   "source": [
    "<h5>M√©thode de recherche avec liste:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fddf60f0-b731-443d-967d-22500db3919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps pour list : 11.410327196121216 secondes\n",
      "Temps/word pour list : 0.0011410327196121216 secondes\n"
     ]
    }
   ],
   "source": [
    "#M√©thode de recherche avec les listes\n",
    "def search_list(redis_client, list, list_key):\n",
    "    start_time = time.time()\n",
    "    for element in list:\n",
    "        position = redis_client.lpos(list_key, element)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Temps d'appartenance avec une liste est: {elapsed_time} secondes\")\n",
    "    average_time_per_membership = elapsed_time / len(list)\n",
    "    print(f\"Temps de chaque mot est: {average_time_per_membership} secondes\")\n",
    "    \n",
    "list_key= \"words:list\"\n",
    "\n",
    "#Test\n",
    "search_list(client_redis, mots_definitions[:10000], list_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330cbd7e-dc8f-4b45-9599-07e34fa6d934",
   "metadata": {},
   "source": [
    "***Remarque:***\n",
    "<p>\n",
    "Suite √† l'insertion des donn√©es dans Redis, nous avons not√© une observation importante concernant l'espace occup√© par chacune. Cette observation est pr√©sent√©e dans <b>la figure 6</b>, le filtre de Bloom occupe un espace m√©moire de 391 kilo-octets (KB). Cette mesure refl√®te la taille n√©cessaire pour stocker les √©l√©ments dans le filtre de Bloom. Parall√®lement, la liste utilis√©e dans notre √©tude occupe 4 m√©gaoctets (MB) d'espace m√©moire.\n",
    "</p>\n",
    "<p>\n",
    "La diff√©rence significative entre l'espace m√©moire occup√© par le filtre de Bloom et celui occup√© par la liste indique des caract√©ristiques distinctes en termes d'efficacit√© de stockage. Le filtre de Bloom semble √™tre une option plus √©conomique en termes d'espace m√©moire, occupant sensiblement moins d'espace que la liste traditionnelle.\n",
    "</p>\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image6.png\"\n",
    "  alt=\"Comparaison de l'espace m√©moire occup√©\"\n",
    "  width=\"500\"\n",
    "  height=\"450\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Figure 6: Comparaison de l'espace m√©moire occup√©<b></h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81c468-6a0a-494b-8a63-8573e7fe1ab3",
   "metadata": {},
   "source": [
    "<h4>Conclusion:</h4>\n",
    "<p>\n",
    "Les r√©sultats de nos fonctions de performance montrent clairement que l'utilisation de Bloom filter offre des performances sup√©rieures pour l'op√©ration de la recherche. L'insertion avec Bloom filter plus lente que celle avec la liste, mais la diff√©rene est minime. En revanche, la recherche avec Bloom filter est extremement rapide par rapport √† la liste, ce qui montre l'efficacit√© de Bloom filter pour les op√©ration d'appartenance.\n",
    "</p>\n",
    "<p>\n",
    "Finalement, l'utilisation de Bloom filter se r√©v√®le avantageuse pour les op√©rations de recherche, offrant aussi une solution performante et √©conome de temps d'ex√©cution.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd77b0b-e909-4a12-8c1a-e32105822506",
   "metadata": {},
   "source": [
    "<h3>5. Publication et souscription</h3>\n",
    "<p>\n",
    "    Le principe de publication et de souscription est un mod√®le de communication entre diff√©rents composants logiciels ou syst√®mes.\n",
    "Il permet √† des parties distinctes de s'√©changer des informations de mani√®re asynchrone, sans qu'elles soient directement coupl√©es les unes aux autres. Dans ce contexte, la situation d√©crite est semblage √† ce qui est repr√©sent√© dans <b> la figure 7</b>. \n",
    "   \n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image7.png\"\n",
    "  alt=\"Publication et souscription\"\n",
    "  width=\"600\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center ;border:1px solid black\"\"/>\n",
    "<h5><b>Figure 7: Publication et souscription<b></h5>\n",
    "</center>\n",
    "</p>\n",
    "<h4>5.1. Sc√©nario d'application: Calcul de la moyenne de CO2:</h4>\n",
    "<p>\n",
    "L'objectif de cette application est de mettre en place le m√©canisme de pub/sub en utilisant deux script. Le premier agit en tant que producteur qui publie de mani√®re p√©riodique des mesures de CO2 en utilisant le canal \"co2_channel\", qui sont g√©n√©r√©es al√©atoirement, le script s'ex√©cute d'une mani√®re continue et al√©atoire avec un intervalle entre 1 et 3 secondes.\n",
    "</p>\n",
    "<p>\n",
    "Le deuxi√®me script fonctionne comme un recepteur, qui recoit les donn√©es. √Ä chaque minute il r√©cup√®re les donn√©es du canal et calcule la moyenne des valeurs de CO2 re√ßues au cours de la d√©rni√®re minute, des d√©rni√®res 30 minutes et la d√©rni√®re heure. Le scipt utilise le canal \"co2_channel\" pour souscrir aux donn√©es publi√©es par le premier script.\n",
    "</p>\n",
    "<p><b>NB:</b> Si vous utilisez jupyter, vous n'avez pas la capacit√© √† ex√©cuter les deux scripts en parall√®le. Pour r√©soudre ce probl√®me, de vous invite √† voir <b>l'Annexe 4</b>.</p>\n",
    "\n",
    "***Premi√®re √©tape: Publication des Donn√©s:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fea50-584e-4a04-ab5f-d1203b355ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import redis\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379) \n",
    "\n",
    "def generate_random_co2_value():\n",
    "    return round(random.uniform(300, 1000))\n",
    "\n",
    "def send_co2():\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    co2_value = generate_random_co2_value()\n",
    "    \n",
    "    # Cr√©er un dictionnaire\n",
    "    data = {'date': current_date, 'co2_value': co2_value}\n",
    "    \n",
    "    # Convertir le dictionnaire en format JSON\n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    r.publish('co2_channel', json_data)\n",
    "\n",
    "while True:\n",
    "    random_seconds = random.uniform(1, 3)\n",
    "    send_co2()\n",
    "    time.sleep(random_seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303cc57-ed08-4676-b3e8-3a43d63ae1bc",
   "metadata": {},
   "source": [
    "***Deuxi√®me √©tape √©tape: Souscription des Donn√©s:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb0b83-5242-4043-af63-3083d42faf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json \n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import schedule\n",
    "\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379) \n",
    "pubsub = r.pubsub()\n",
    "channel = 'co2_channel'\n",
    "pubsub.subscribe(channel)\n",
    "historique=[]\n",
    "\n",
    "def get_data():\n",
    "    message = pubsub.get_message()\n",
    "    if(message and message.get('data') and message.get('data') != 1):\n",
    "        data = json.loads(message.get('data'))\n",
    "        msg = {\"date\": datetime.strptime(data['date'], '%Y-%m-%d %H:%M:%S'), \"co2_value\": data.get(\"co2_value\")}\n",
    "        historique.insert(0, msg)\n",
    "\n",
    "def get_last_n_minutes(minutes, historique):\n",
    "    now = datetime.now()\n",
    "    time_threshold = now - timedelta(minutes=minutes)\n",
    "    return [item for item in historique if item['date'] >= time_threshold]\n",
    "\n",
    "def calculate_avg(historique):\n",
    "    co2_values = [item['co2_value'] for item in historique]\n",
    "    return sum(co2_values) / len(co2_values)\n",
    "\n",
    "def calculate():\n",
    "    if(len(historique) > 0):\n",
    "        last_1_minutes = get_last_n_minutes(1, historique)\n",
    "        avg_last_1_minutes = calculate_avg(last_1_minutes)\n",
    "\n",
    "        last_30_minutes = get_last_n_minutes(30, historique)\n",
    "        avg_last_30_minutes = calculate_avg(last_30_minutes)\n",
    "\n",
    "        last_1_hour = get_last_n_minutes(60, historique)\n",
    "        avg_last_1_hour = calculate_avg(last_1_hour)\n",
    "\n",
    "        print(\"Derni√®re minute: \" + str(round(avg_last_1_minutes, 1)))\n",
    "        print(\"Derni√®res 30 minutes: \" + str(round(avg_last_30_minutes, 1)))\n",
    "        print(\"Derni√®re heure: \" + str(round(avg_last_1_hour, 1)))\n",
    "        print(\"--------------------------\")\n",
    "    \n",
    "\n",
    "schedule.every(1).minutes.do(calculate)\n",
    "\n",
    "while True:\n",
    "    get_data()\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f819152-92dd-4a56-a7a1-92f5f4f40dbd",
   "metadata": {},
   "source": [
    "<h4>Conclusion:</h4>\n",
    "<p>\n",
    "En conclusion, les r√©sultats obtenus d√©montrent l'efficacit√© du m√©canisme pub/sub mis en place. Le script de souscription (subscribe) r√©ussit √† recevoir de mani√®re fiable les mesures de CO2 publi√©es par le script de publication (publish) sur le canal \"co2_channel\". \n",
    "</p>\n",
    "<p>\n",
    "La flexibilit√© du canal \"co2_channel\" se r√©v√®le particuli√®rement avantageuse, car il peut √™tre utilis√© avec plusieurs instances des scripts de mani√®re simultan√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29133b-82b6-475c-bd28-688aa881cbab",
   "metadata": {},
   "source": [
    "<h1>III. D√©couverte de la base de donn√©e MongoDB:</h1>\n",
    "<p>\n",
    "MongoDB est une base de donn√©es orient√©e documents. En clair, vous b√©n√©ficiez de la scalabilit√© et de la flexibilit√© que vous voulez, avec les fonctions d‚Äôinterrogation et d‚Äôindexation qu‚Äôil vous faut.\n",
    "</p>\n",
    "<p>\n",
    "Alors, √™tes-vous pr√™t √† plonger dans l'aventure MongoDB ? Dans un instant, nous allons mettre en pratique ces concepts et ma√Ætriser l'art de la gestion de donn√©es avec agilit√©. Attachez vos ceintures, c'est parti ! üöÄ\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba7819-076e-4542-b635-dc6ef60f6d3c",
   "metadata": {},
   "source": [
    "<h3>1. Installation:</h3>\n",
    "<p>\n",
    "La proc√©dure d√©taill√©e est disponible dans <b>l'Annexe 3</b>. Pour une installation efficace de MongoDB, je vous recommande d'utiliser Docker Compose et MongoDB Compass pour la visualisation. Cette approche simplifi√©e vous permettra de d√©ployer MongoDB dans des conteneurs Docker tout en facilitant la gestion avec Docker Compose.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787205c-ce0d-4973-801f-40b3514deae7",
   "metadata": {},
   "source": [
    "<h3>2. Commandes fondamentales  de MongoDB:</h3>\n",
    "<p>\n",
    "<p>Avant de commencer, il est essentiel de connaitre le format de stockage de MongoDB. Les informations sont stock√©es dans des documents au format JSON (plus exactement BSON, une version binaire du JSON).\n",
    "<p>\n",
    "</p>\n",
    "<H4> 2.1. Cr√©ation de collection:</H4>\n",
    "<p>   \n",
    "MongoDB est structur√© autour de 3 √©l√©ments : <b> le document</b>, <b>la collection</b> et<b> la database.</b>\n",
    "\n",
    "    - Une database contient une ou plusieurs collections.\n",
    "    - Une collection regroupe un ensemble de documents.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48514098-a1ae-4373-978b-6aad538b5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d7ed6fd-2da4-4979-9ce2-b3002e2d0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "clientDB = pymongo.MongoClient(\"<db_userName>:<db_password>@<db_url>/\")\n",
    "mydb = clientDB[\"BUT3\"]\n",
    "mycollection = mydb[\"Informatique\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b8835-61c3-40ae-8c5d-a32eeefb98c9",
   "metadata": {},
   "source": [
    "<H4> 2.2. M√©thodes d'insertion:</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af831a1-b92b-42f5-9632-d319e705e66b",
   "metadata": {},
   "source": [
    "<H5> 2.2.1. Insertion d'un objet JSON:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f86e3483-15fa-44f6-b561-9a38aad03fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6585421f43341b608c85fccb'), 'name': 'ikram', 'address': 'paris'}\n",
      "{'_id': ObjectId('6585422643341b608c85fccc'), 'name': 'ikram', 'address': 'paris'}\n"
     ]
    }
   ],
   "source": [
    "mycollection.insert_one({ \"name\": \"ikram\", \"address\": \"paris\" })\n",
    "\n",
    "for y in mycollection.find():\n",
    "  print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02db48-569b-41b4-b862-4a88af0cab37",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>La figure 8</b> montre une d√©monstration d'insertion d'un objet JSON dans MongoDB, \"BUT3\" repr√©sente le nom de la base de donn√©es, tandis que \"INFORMATIQUE\" est le nom de la collection au sein de cette base de donn√©es. L'op√©ration d'insertion concerne un unique document, sous la forme d'un objet JSON, qui est ajout√© √† la collection sp√©cifi√©e. Il est not√© que cet objet est ins√©r√© avec un index par d√©faut, sugg√©rant probablement l'utilisation d'un index automatique assign√© par MongoDB lors de l'insertion si aucun index explicite n'est sp√©cifi√©.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b06ec3-74e9-4604-bad7-e33e09a6c9d4",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image8.png\"\n",
    "  alt=\"D√©monstration d'insertion des donn√©e dans MongoDB\"\n",
    "  width=\"700\"\n",
    "  height=\"550\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 8: D√©monstration d'insertion des donn√©e dans MongoDB<b></h5>  \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbbed7-5d18-4ea2-bdd6-8d0d7d6a07cb",
   "metadata": {},
   "source": [
    "<H5> 2.2.2. Insertion d'un tableau d'objet:</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80b1ddb4-6f44-446b-b54a-079131e456ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('658542a243341b608c85fcd5'), 'cle': '001', 'lieu': 'Mar 1'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcd6'), 'cle': '001', 'lieu': 'Rane 1'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcd7'), 'cle': '002', 'lieu': 'Mar 2'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcd8'), 'cle': '002', 'lieu': 'Rane 2'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcd9'), 'cle': '003', 'lieu': 'Mar 3'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcda'), 'cle': '003', 'lieu': 'Rane 3'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcdb'), 'cle': '003', 'lieu': 'Lila 1'}\n",
      "{'_id': ObjectId('658542a243341b608c85fcdc'), 'cle': '004', 'lieu': 'Mar 4'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "mydb = clientDB[\"Test_json\"]\n",
    "mycollection = mydb[\"json\"]\n",
    "\n",
    "with open(\"json/json1.json\") as j1:\n",
    "    json1 = json.load(j1)\n",
    "    mycollection.insert_many(json1)  \n",
    "    \n",
    "res= mycollection.find()\n",
    "for element in res:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc4e22-06be-42ab-ac40-f1b886528f75",
   "metadata": {},
   "source": [
    "<p>\n",
    "<b>La figure 8</b> repr√©sente le flux de travail de notre script d'insertion d'un tableau d'objets. Chaque objet JSON est stock√© sous forme de document dans la collection MongoDB et chaque document poss√®de un identifiant unique. Si aucun identifiant n'est sp√©cifi√© pour un document, MongoDB attribue automatiquement un ID unique √† ce document.\n",
    "\n",
    "Cette approche assure une int√©gration efficace des donn√©es JSON dans MongoDB, offrant une flexibilit√© et une granularit√© dans la manipulation des documents au sein de la collection \"Test_json\". \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a4ae8-bf67-496e-8e28-83887b57dedd",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/image9.png\"\n",
    "  alt=\"D√©monstration de l'insertion de fichier JSON dans MongoDB\"\n",
    "  width=\"700\"\n",
    "  height=\"550\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 9: D√©monstration de l'insertion de fichier JSON dans MongoDB<b></h5>  \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c5cf4-3997-423c-b1f6-12eac616c417",
   "metadata": {},
   "source": [
    "<H4> 2.3. R√©cup√©rer le nombre de documents d'une collection:</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ad62ec9-cbf2-4d84-a7f7-d7f77fbf0396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "json_count = mycollection.count_documents({})\n",
    "print(json_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5ddb0-82d1-4a79-9245-ccf5f6ceabb7",
   "metadata": {},
   "source": [
    "<H4> 2.4. Supprimer le contenu d'une collection:</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93a2cb-931c-48eb-8d30-e0b0242ea479",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete= mycollection.delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf3a5a-3406-42dc-b964-a4756841260e",
   "metadata": {},
   "source": [
    "<h3>3. La jointure des Objets JSON avec MongoDB:</h3>\n",
    "<p>\n",
    "MongoDB, offre une solution flexible pour effectuer des op√©ration de jointure √† l'aide de son pipeline d'agr√©gation, qui permet de fusionner des donn√©es provenant de diff√©rentes collections.\n",
    "</p>\n",
    "<p>\n",
    "Tout d'abord, il faut utiliser <b>\"lookup\"</b> qui permet de sp√©cifier la collection externe √† joindre et les champs qui serviront de cl√©s de jointure. <b>\"project\"</b> pour s√©lectionner les champs √† inclure dans le r√©sultat final. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf774313-ffd0-4f84-a591-e4ec5a1a6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import pymongo\n",
    "\n",
    "clientDB = pymongo.MongoClient(\"mongodb://<db_userName>:<db_password>@<db_url>/\")\n",
    "mydb = clientDB[\"test_jointure\"]\n",
    "collection_json1 = mydb[\"json1\"]  \n",
    "collection_json2 = mydb[\"json2\"] \n",
    "\n",
    "with open(\"json/json1.json\") as j1:\n",
    "    json1 = json.load(j1)\n",
    "    collection_json1.insert_many(json1)  \n",
    "with open(\"json/json2.json\") as j2:\n",
    "    json2 = json.load(j2)\n",
    "    collection_json2.insert_many(json2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed651bcb-9ba8-483e-b167-8e5285923488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('658542f143341b608c85fcf8'), 'cle': '001', 'lieu': 'Mar 1', 'info': \"L'info 1\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcf9'), 'cle': '001', 'lieu': 'Rane 1', 'info': \"L'info 1\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcfa'), 'cle': '002', 'lieu': 'Mar 2', 'info': \"L'info 2\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcfb'), 'cle': '002', 'lieu': 'Rane 2', 'info': \"L'info 2\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcfc'), 'cle': '003', 'lieu': 'Mar 3', 'info': \"L'info 3\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcfd'), 'cle': '003', 'lieu': 'Rane 3', 'info': \"L'info 3\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcfe'), 'cle': '003', 'lieu': 'Lila 1', 'info': \"L'info 3\"}\n",
      "{'_id': ObjectId('658542f143341b608c85fcff'), 'cle': '004', 'lieu': 'Mar 4', 'info': \"L'info 4\"}\n"
     ]
    }
   ],
   "source": [
    "resultat = collection_json1.aggregate([\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"json2\",\n",
    "            \"localField\": \"cle\",\n",
    "            \"foreignField\": \"cle\",\n",
    "            \"as\": \"json2\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$unwind\": \"$json2\"\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"cle\": 1,\n",
    "            \"lieu\": 1,\n",
    "            \"info\": \"$json2.info\"\n",
    "        }\n",
    "    }\n",
    "])\n",
    "collection_json3 = mydb[\"json_resultat\"] \n",
    "collection_json3.insert_many(resultat)\n",
    "\n",
    "res= collection_json3.find()\n",
    "for element in res:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f69cc-3ee6-42ba-8692-af624dce938b",
   "metadata": {},
   "source": [
    "<h3>4. √âtude des performances de MongoDB:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410a8d6-e904-4b91-80fb-d7ee6a425bcd",
   "metadata": {},
   "source": [
    "<p>Notre objectif est d'analyser l'impact des index sur la performance pour la r√©cup√©ration de grandes quantit√©s de donn√©es. Nous comparerons les performances de MongoDB avec index et sans index en utilisant le m√™me dictionnaire que celui employ√© pr√©c√©demment avec Redis: <a href=\"rali.iro.umontreal.ca/DEM//DEM-1_1.csv\">Cliquez ici.</a>.\n",
    "</p>\n",
    "<p>\n",
    "La probl√©matique centrale de notre √©tude est la suivante : Comment les index influencent-ils la performance pour la r√©cup√©ration de 100 000 mots dans le contexte de MongoDB ? Afin de r√©pondre √† cette question, nous allons mettre en ≈ìuvre un test approfondi visant √† mesurer les temps d'appartenance des mots pour chaque configuration, avec et sans index.\n",
    "</p>\n",
    "<p>\n",
    "Dans cette d√©marche comparative, notre objectif est de d√©terminer laquelle des m√©thodes offre la meilleure performance en termes de temps d'acc√®s et de r√©ponses?\n",
    "</p>\n",
    "<p>\n",
    "En utilisant le m√™me jeu de donn√©es que celui utilis√© dans l'√©tude pr√©c√©dente avec Redis, nous pourrons comparer directement les r√©sultats obtenus entre les deux bases de donn√©es. Cette analyse comparative nous permettra de prendre des d√©cisions √©clair√©es quant √† l'utilisation ou non d'index dans des sc√©narios similaires avec MongoDB, contribuant ainsi √† optimiser la gestion de grandes quantit√©s de donn√©es.</p>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9f36f-cd27-4163-bf43-603a8fe97036",
   "metadata": {},
   "source": [
    "***Premi√®re √©tape: √âtude de la performance sans index :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "380a8ae7-0a27-47a7-8012-53a6454ebd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6585431143341b608c85ff0d'), 'M': '√† la rencontre de'}\n",
      "temps de recherche est: 0.10278797149658203 secondes\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from pymongo import MongoClient\n",
    "\n",
    "clientDB = MongoClient(\"mongodb://<db_userName>:<db_password>@<db_url>/\")\n",
    "mydb_one = clientDB[\"dictionnaire\"]\n",
    "mycollection_one = mydb_one[\"collection_without_index\"] \n",
    "\n",
    "with open(\"json/my_json.json\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "res=mycollection_one.insert_many(data)\n",
    "\n",
    "def search_by_name_without_index(word):\n",
    "    temps_debut=time.time()\n",
    "    element= mycollection_one.find({\"M\": word},{\"M\":1})\n",
    "    for elm in element:\n",
    "        print(elm)\n",
    "    temps_fin=time.time()\n",
    "    print(\"temps de recherche est: \"+str(temps_fin-temps_debut)+\" secondes\")\n",
    "\n",
    "search_by_name_without_index(\"√† la rencontre de\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d72c3d-75af-4ba8-827c-17f81d7a7066",
   "metadata": {},
   "source": [
    "***Deuxi√®me √©tape: √âtude de la performance avec index :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8fa6b60-d96e-4ca4-ad9b-47371f9406a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6585431643341b608c88363b'), 'M': '√† la rencontre de'}\n",
      "{'_id': ObjectId('6585432543341b608c8a6d69'), 'M': '√† la rencontre de'}\n",
      "temps de recherche est: 0.001825094223022461 secondes\n"
     ]
    }
   ],
   "source": [
    "clientDB = MongoClient(\"mongodb://<db_userName>:<db_password>@<db_url>/\")\n",
    "mydb_two = clientDB[\"dictionnaire\"]\n",
    "mycollection_two = mydb_two[\"collection_with_index\"] \n",
    "\n",
    "with open(\"json/my_json.json\") as file:\n",
    "        data1 = json.load(file)\n",
    "    \n",
    "res1=mycollection_two.insert_many(data1)\n",
    "\n",
    "#Cr√©ation d'index\n",
    "index = [(\"M\",1)]\n",
    "mycollection_two.create_index(index)\n",
    "\n",
    "def search_by_name_with_index(word):\n",
    "    temps_debut=time.time()\n",
    "    element= mycollection_two.find({\"M\": word},{\"M\":1})\n",
    "    for elm in element:\n",
    "        print(elm)\n",
    "    temps_fin=time.time()\n",
    "    print(\"temps de recherche est: \"+str(temps_fin-temps_debut)+\" secondes\")\n",
    "\n",
    "search_by_name_with_index(\"√† la rencontre de\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e9526-c7f2-4cdd-a4b2-da4b4c9d5d1a",
   "metadata": {},
   "source": [
    "<h4>R√©sultat:</h4>\n",
    "<p>\n",
    "Les r√©sultats obtenus mettent en √©vidence une distinction notable dans les performances entre l'utilisation d'index et l'absence d'index. Lorsque les index sont utilis√©s, le temps n√©cessaire pour v√©rifier l'appartenance d'une donn√©e est extremement court. En revanche, sans l'utilisation d'index, le temps augmente consid√©rablement.\n",
    "</p>\n",
    "<p>\n",
    "Notre √©tude d√©montre clairement l'impact positif des index sur la performance des op√©rations d'appartenance de donn√©es dans MongoDB. Les r√©sultats montrent une r√©duction significative du temps d'acc√®s, passant de ‚âà 0.080 secondes sans index √† seulement ‚âà 0.002 secondes avec index. Ces conclusions soulignent l'importance strat√©gique de l'utilisation d'index pour optimiser les temps de recherche, offrant ainsi des pistes concr√®tes pour am√©liorer l'efficacit√© op√©rationnelle de notre syst√®me de gestion de donn√©es.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461328c-0531-4463-ad37-4cf6fccb6ebf",
   "metadata": {},
   "source": [
    "<p>\n",
    "Pour obtenir une vision plus clair des performances entre une recherche avec et sans index, nous nous appuierons sur l'outil MongoDB Compass qui est un outil interactif qui permet d'interroger, d'optimiser et d'analyser nos donn√©es MongoDB. Dans <b>la Figure 10</b>, nous observons une recherche sans index, indiquant que le moteur de recherche de MongoDB a parcouru la totalit√© des 145 197 documents pour trouver le r√©sultat requis, avec un temps d'ex√©cution de 118 ms. En contraste, <b>la Figure 11</b>, illustrant la recherche avec index, r√©v√®le une am√©lioration significative. Gr√¢ce √† l'utilisation de l'index 'M', le moteur de recherche de MongoDB a consult√© uniquement les documents pertinents, permettant ainsi une recherche d'une rapidit√© remarquable de 0 ms.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0447a9e-8a09-46c5-a865-5de85981452e",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img\n",
    "  src=\"images/insertion_sans_index.png\"\n",
    "  alt=\"D√©monstration de l'insertion de fichier JSON dans MongoDB\"\n",
    "  width=\"700\"\n",
    "  height=\"550\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 10: D√©tails de la recherche sans index <b></h5>  \n",
    "</center>\n",
    "    <br>\n",
    "    <br>\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/insertion_index.png\"\n",
    "  alt=\"D√©monstration de l'insertion de fichier JSON dans MongoDB\"\n",
    "  width=\"700\"\n",
    "  height=\"550\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "<h5><b>Figure 11: D√©tails de la recherche avec index  <b></h5>  \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79184fef-2ad2-49d7-9734-95ad1754ae40",
   "metadata": {},
   "source": [
    "<h4> Conclusion:</h4>\n",
    "<div style=\"text-align: justify\">\n",
    "<p>\n",
    "Pour conclure, notre pr√©sente √©tude sur MongoDB, en compl√©ment de l'√©tude pr√©c√©dente sur Redis, s'est concentr√©e sur la comparaison du temps d'appartenance entre les technologies Redis avec Bloom Filter, MongoDB sans Index, et MongoDB avec Index.\n",
    "</p>\n",
    "<p>\n",
    "Les r√©sultats indiquent que Redis avec Bloom filter excelle dans la rapidit√© des op√©rations d'appartenance. Cependant, la gestion prudente de la consommation de m√©moire est n√©cessaire.\n",
    "</p>\n",
    "<p>\n",
    "D'un autre c√¥t√©, MongoDB avec index a d√©montr√© une am√©lioration notable des performances, particuli√®rement b√©n√©fique pour des requ√™tes complexes, bien que cette optimisation s'accompagne d'une augmentation de l'utilisation de l'espace disque.\n",
    "</p>\n",
    "<p>\n",
    "MongoDB sans index, pr√©sente des limitations √©videntes lorsque la taille de la base de donn√©es augmente, comme notre cas d‚Äô√©tude, mais cette m√©thode viable pour des bases de donn√©es plus petites ou des op√©rations simples.\n",
    "</p>\n",
    "<p>\n",
    "Finalement, le choix entre ces solutions d√©pendra des besoins sp√©cifiques de l'application, mettant en balance la rapidit√©, la consommation de m√©moire et l'utilisation de l'espace disque.\n",
    "</p>\n",
    "</div>\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/redis_mogodb.jpg\"\n",
    "  alt=\"Redis_vs_mongodb\"\n",
    "  width=\"700\"\n",
    "  height=\"550\" \n",
    "  style=\"text-align: center ;border:1px solid black\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ba4bc-58a5-4e25-8279-b4d50685cb33",
   "metadata": {},
   "source": [
    "<h3>5. Publication et souscription:</h3>\n",
    "<p>\n",
    "Contrairement √† Redis, MongoDB ne prend pas en charge nativement le mod√®le pub/sub. Mais malg√© cette absence, il existe des solutions √† developper par nous les d√©veloppeurs pour attreindre des fonctionnalit√©s similaires.\n",
    "</p>\n",
    "\n",
    "***Solution mise en oeuvre avec MongoDB:***\n",
    "<p>\n",
    "<b>Change Streams:</b> C'est une fonctionnalit√© MongoDB qui permet de suivre les changements au niveau de la base de donn√©es en temps r√©el, alors, ils sont utilis√©s pour d√©tecter les changements dans une collection et d√©clencher des actions en cons√©quences. Cependant, pour activer les Change Streams, il est imp√©ratif d'activer le syst√®me r√©plicaset de MongoDB. Je vous invite √† consulter<a href=\"https://www.mongodb.com/docs/manual/changeStreams/\"> le lien suivant </a>pour plus des informations.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e210b-2efa-4e1e-8a99-c0010b801ff1",
   "metadata": {},
   "source": [
    "<p>Si vous utilisez jupyter, vous n'avez pas la capacit√© √† ex√©cuter les deux scripts en parall√®le. Pour r√©soudre ce probl√®me, de vous invite √† voir <b>l'Annexe 4</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4fada6e1-fe67-49eb-a0ac-017a98b0ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test publisher:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bef459-f4e4-4d17-9a36-3d5f42faf1df",
   "metadata": {},
   "source": [
    "<b>publisher_mongodb.py<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b76e2-8495-4043-8914-07f72aea8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "import time\n",
    "import certifi\n",
    "\n",
    "def connectToMongodb():\n",
    "    uri=\"mongodb+srv://<db_name>:<db_password>@<db_url>/\"\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'), tlsCAFile=certifi.where())\n",
    "    try:\n",
    "        client.admin.command('ping')\n",
    "        print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return client\n",
    "\n",
    "# Connexion √† la base de donn√©es\n",
    "client = connectToMongodb()\n",
    "collection = client[\"mydatabase\"]['co2_channel']\n",
    "\n",
    "def generate_random_co2_value():\n",
    "    return round(random.uniform(300, 1000))\n",
    "\n",
    "def send_co2():\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    co2_value = generate_random_co2_value()\n",
    "    \n",
    "    # Cr√©er un dictionnaire\n",
    "    data = {'date': current_date, 'co2_value': co2_value}\n",
    "\n",
    "    #Insertion dans le dictionnaire  \n",
    "    collection.insert_one(data)\n",
    "\n",
    "while True:\n",
    "    random_seconds = random.uniform(1, 3)\n",
    "    send_co2()\n",
    "    time.sleep(random_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "93f19174-fc63-4048-b35c-0b6a5099c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test subscriber:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1a5ca-146a-4120-aa83-9571524f63ba",
   "metadata": {},
   "source": [
    "<b>subscriber_monodb.py</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcd34f-d5aa-404d-9ac5-e03a5f3a80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from datetime import datetime\n",
    "\n",
    "import schedule\n",
    "import certifi\n",
    "\n",
    "def connectToMongodb():\n",
    "    uri=\"mongodb+srv://<db_name>:<db_password>@<db_url>/\"\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'), tlsCAFile=certifi.where())\n",
    "    try:\n",
    "        client.admin.command('ping')\n",
    "        print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return client\n",
    "\n",
    "# Connexion √† la base de donn√©es\n",
    "client = connectToMongodb()\n",
    "collection = client[\"mydatabase\"]['co2_channel']\n",
    "\n",
    "# Tableau qui va stocker les donn√©es re√ßu du publisher\n",
    "historique=[]\n",
    "\n",
    "# Recup√©ration des donn√©es de MongoDB (document_id: id du document inser√©)\n",
    "def get_data(document_id):\n",
    "    message = collection.find_one({\"_id\": document_id})\n",
    "    if(message):\n",
    "        data = message\n",
    "        msg = {\"date\": datetime.strptime(data['date'], '%Y-%m-%d %H:%M:%S'), \"co2_value\": data.get(\"co2_value\")}\n",
    "        historique.insert(0, msg)\n",
    "\n",
    "def get_last_n_minutes(minutes, historique):\n",
    "    now = datetime.now()\n",
    "    time_threshold = now - timedelta(minutes=minutes)\n",
    "    return [item for item in historique if item['date'] >= time_threshold]\n",
    "\n",
    "def calculate_avg(historique):\n",
    "    co2_values = [item['co2_value'] for item in historique]\n",
    "    return sum(co2_values) / len(co2_values)\n",
    "\n",
    "def calculate():\n",
    "    if(len(historique) > 0):\n",
    "        last_1_minutes = get_last_n_minutes(1, historique)\n",
    "        avg_last_1_minutes = calculate_avg(last_1_minutes)\n",
    "\n",
    "        last_30_minutes = get_last_n_minutes(30, historique)\n",
    "        avg_last_30_minutes = calculate_avg(last_30_minutes)\n",
    "\n",
    "        last_1_hour = get_last_n_minutes(60, historique)\n",
    "        avg_last_1_hour = calculate_avg(last_1_hour)\n",
    "\n",
    "        print(\"Derni√®re minute: \" + str(round(avg_last_1_minutes, 1)))\n",
    "        print(\"Derni√®res 30 minutes: \" + str(round(avg_last_30_minutes, 1)))\n",
    "        print(\"Derni√®re heure: \" + str(round(avg_last_1_hour, 1)))\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "schedule.every(1).second.do(calculate)\n",
    "\n",
    "# Cr√©er un Change Stream sur la collection qui ecoute que les op√©ration de type insert\n",
    "change_stream = collection.watch([{\"$match\": {\"operationType\": \"insert\"}}])\n",
    "\n",
    "# G√©rer les √©v√©nements de changement\n",
    "for change in change_stream:\n",
    "    document_id = change[\"documentKey\"][\"_id\"]\n",
    "    get_data(document_id)\n",
    "    #Pour lancer le schedule\n",
    "    schedule.run_pending()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9b12a-a24d-4562-8d9e-998026065ff6",
   "metadata": {},
   "source": [
    "<h4>Conclusion:</h4>\n",
    "<p>\n",
    "En conclusion, l'exploration des bases de donn√©es NoSQL, en particulier MongoDB et Redis, a r√©v√©l√© des caract√©ristiques distinctes et des performances sp√©cifiques. MongoDB, en tant que syst√®me de gestion de base de donn√©es orient√© document, a montr√© une efficacit√© notable pour les op√©rations de lecture et d'√©criture complexes, avec une flexibilit√© accrue dans la mod√©lisation des donn√©es. D'autre part, Redis, en mettant en ≈ìuvre des structures de donn√©es en m√©moire, a d√©montr√© des performances exceptionnelles pour les op√©rations de lecture rapide, en tirant parti de structures telles que les bloom filters pour am√©liorer l'efficacit√© des op√©rations d'appartenance.\n",
    "</p>\n",
    "</p>\n",
    "<p>\n",
    "L'analyse comparative des performances avec et sans index dans MongoDB a r√©v√©l√© l'impact crucial des indices sur l'efficacit√© des requ√™tes. Cette constatation souligne l'importance de la conception r√©fl√©chie de l'indexation pour optimiser les performances des requ√™tes dans un environnement MongoDB.\n",
    "</p>\n",
    "<p>\n",
    "Par ailleurs, l'√©tude de la fonctionnalit√© pub/sub dans Redis a mis en √©vidence la capacit√© de ce syst√®me √† fournir une communication asynchrone efficace entre les diff√©rentes parties de l'application, offrant ainsi une flexibilit√© pr√©cieuse dans le traitement des donn√©es.\n",
    "</p>\n",
    "<p>\n",
    "En somme, l'utilisation judicieuse de ces bases de donn√©es NoSQL en fonction des exigences sp√©cifiques de chaque application est cruciale. MongoDB et Redis offrent des avantages distincts, et le choix entre eux d√©pendra des besoins pr√©cis en termes de performances, de structure des donn√©es et de fonctionnalit√©s requises. Cette √©tude approfondie fournit des insights pr√©cieux pour vous guidez dans la prise de d√©cision concernant le choix de la base de donn√©es NoSQL la mieux adapt√©e √† vos projets.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c257c-3aea-4d32-a834-605c0a5d97e1",
   "metadata": {},
   "source": [
    "<h2>Table des Annexes:</h2>\n",
    "<h4>Annexes 1: Installation de Redis</h4>\n",
    "\n",
    "- Cr√©ez un fichier `Dockerfile` avec la configuration.<br>\n",
    "\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image10.png\"\n",
    "  alt=\"D√©ploiement de Redis avec Dokerfile\"\n",
    "  width=\"400\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Annexes 1: D√©ploiement de Redis avec Dokerfile<b></h5>  \n",
    "</center>\n",
    "    \n",
    "<h4>Annexes 2:  Installation de Redis (suite)</h4>\n",
    "\n",
    "- Cr√©ez un fichier `DockerCompose.yml` avec la configuration.<br>\n",
    "<p>\n",
    "   \n",
    "</p>\n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image11.png\"\n",
    "  alt=\"Orchestration de d√©ploiement de Redis\"\n",
    "  width=\"400\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Annexes 2: Orchestration de d√©ploiement de Redis<b></h5>\n",
    "</center>\n",
    "    \n",
    "<h4>Annexes 3: Installation de MongoDB</h4>\n",
    "<p>\n",
    "    \n",
    "1. Installation de MongoDB avec Docker Compose :\n",
    "    - Cr√©ez un fichier `docker-compose.yml`avec la configuration.<br>\n",
    "    - Ex√©cutez la commande `docker-compose up -d` pour d√©marrer MongoDB avec Docker Compose.<br>\n",
    "    \n",
    "<center>\n",
    "<img\n",
    "  src=\"images/image12.png\"\n",
    "  alt=\"Installation de MongoDB\"\n",
    "  width=\"400\"\n",
    "  height=\"350\" \n",
    "  style=\"text-align: center\"/>\n",
    "<h5><b>Annexes 3: Installation de MongoDB<b></h5>\n",
    "</center>\n",
    "    \n",
    "2. Utilisation de MongoDB Compass pour la visualisation :\n",
    "   - Installez MongoDB Compass depuis le site officiel <a href=\"https://www.mongodb.com/products/tools/compass\">Cliquez ICI.</a> \n",
    "   - Lancez MongoDB Compass et connectez-vous √† votre instance MongoDB avec l'adresse `localhost:27017` et les identifiants du fichier `docker-compose.yml`.\n",
    "\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adba2e0-2449-441f-9e62-800d54cd0003",
   "metadata": {},
   "source": [
    "<h4>Annexes 4: √âxecution des scripts Pub/Sub </h4>\n",
    "<p>\n",
    "    \n",
    "1. Positionnement dans le r√©peroire:\n",
    "- Ouvrez un terminal ou une console dans le r√©pertoire o√π se trouvent les scripts<br>\n",
    "- Ex√©cutez la commande `$cd Path/repertoire` .<br>\n",
    "    \n",
    "2. Lancement du Script Subscriber :\n",
    "- Ex√©cutez la commande `$python3 publisher_mongodb.py` .<br> \n",
    "  \n",
    "3. Lancement du Script Publisher :\n",
    "- Dans un autre terminal, ex√©cutez la commande `$python3 subscriber_monodb.py` .<br> \n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
